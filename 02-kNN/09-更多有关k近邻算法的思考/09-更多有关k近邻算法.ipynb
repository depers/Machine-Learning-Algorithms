{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09-更多有关k近邻算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k近邻算法的优势\n",
    "\n",
    "* 解决分类问题\n",
    "* 天然可以解决多分类问题\n",
    "* 思想简单，效果强大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用K近邻算法解决回归问题\n",
    "\n",
    "sklearn中的[KNeighborsRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K近邻算法的缺点\n",
    "\n",
    "* 最大的缺点：效率低下  \n",
    "> 如果训练集有m个样本，n个特征，则预测每一个新的数据，需要O(m*n)\n",
    "> 优化：使用树结构：KD-Tree, Ball-Tree\n",
    "\n",
    "* 缺点2：高度数据相关,对于outlier极度敏感\n",
    "* 缺点3：预测结果不具有可解释性\n",
    "* 缺点4：维数灾难（随着维度的增加，“看似相近”的两个点之间的距离越来越大）\n",
    "> 解决方法：降维\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习流程回顾\n",
    "![机器学习流程](./illustration.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
